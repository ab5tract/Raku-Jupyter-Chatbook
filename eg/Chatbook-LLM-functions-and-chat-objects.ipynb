{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM functions and chat objects\n",
    "\n",
    "Anton Antonov   \n",
    "[\"Jupyter::Chatbook\" Raku package at GitHub](https://github.com/antononcube/Raku-Jupyter-Chatbook)   \n",
    "August, September 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we show how Large Language Models (LLMs) functions and LLM chat objects can be created and used in a notebook. This notebook is a ***chatbook*** created with the Raku package [\"Jupyter::Chatbook\"](https://raku.land/zef:antononcube/Jupyter::Chatbook), [AAp1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"streamlined\" way to utilize LLMs is with the package[\"LLM::Functions\"](https://raku.land/zef:antononcube/LLM::Functions), [AA1, AAp2]. I.e. without using specific, dedicated packages for accessing LLMs like those of [\"WWW::OpenAI\"](https://raku.land/zef:antononcube/WWW::OpenAI), [AAp3], and [\"WWW::PaLM\"](https://raku.land/zef:antononcube/WWW::PaLM), [AAp4].\n",
    "\n",
    "Chatbooks load in their initialization phase the package \n",
    "[\"LLM::Functions\"](https://github.com/antononcube/Raku-LLM-Functions), [AAp2].\n",
    "Also, in the initialization phase are loaded the packages \n",
    "[\"Clipboard\"](https://github.com/antononcube/Raku-Clipboard), [AAp5],\n",
    "[\"Data::Translators\"](https://github.com/antononcube/Raku-Data-Translators), [AAp6],\n",
    "[\"Data::TypeSystem\"](https://github.com/antononcube/Raku-Data-Translators), [AAp7],\n",
    "[\"Text::Plot\"](https://github.com/antononcube/Raku-Text-Plot), [AAp8],\n",
    "and \n",
    "[\"Text::SubParsers\"](https://github.com/antononcube/Raku-Text-SubParsers), [AAp9], \n",
    "that can be used to post-process LLM outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** For LLM functions and chat objects the functionalities of [\"Jupyter::Kernel\"](https://github.com/bduggan/raku-jupyter-kernel), [BDp1], suffice. In other words, the \"chatbook\" extensions provided by \"Jupyter::Chatbook\", [AAp1], are not needed.\n",
    "\n",
    "**Remark:** The LLM functions and chat objects are provided by the package [\"LLM::Functions\"](https://raku.land/zef:antononcube/LLM::Functions), [AA1, AAp2], which in turn uses the packages [\"WWW::OpenAI\"](https://raku.land/zef:antononcube/WWW::OpenAI), [AAp3], and [\"WWW::PaLM\"](https://raku.land/zef:antononcube/WWW::PaLM), [AAp4].\n",
    "\n",
    "**Remark:** The default API keys for the LLM functions and chat objects are taken from the Operating System (OS) environmental variables `OPENAI_API_KEY` and `PALM_API_KEY`. The api keys can also be specified using LLM evaluator and configuration options and objects; see [AA1, AAp2].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------ \n",
    "\n",
    "## LLM functions\n",
    "\n",
    "\n",
    "\n",
    "Here is an example of an LLM function that takes 3 arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|5576882966416) ... }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &f1 = llm-function({\"What is the $^a of $^b in $^c. Give numerical answer only.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the LLM function defined above is \"concretized\" with argument values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "3.14 trillion"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "&f1('GDP', 'California, USA', '2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call repeatedly `&f1` in order to Lake Mead levels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990 => \n",
       "\n",
       "1,212.68 feet 1991 => \n",
       "\n",
       "1095.6 feet 1992 => \n",
       "\n",
       "1045.72 ft 1993 => \n",
       "\n",
       "1074.18 1994 => \n",
       "\n",
       "1,097.88 feet 1995 => \n",
       "\n",
       "1078.35 feet 1996 => \n",
       "\n",
       "1,113.79 feet 1997 => \n",
       "\n",
       "1096.17 feet 1998 => \n",
       "\n",
       "1093.38 feet 1999 => \n",
       "\n",
       "1058.1 feet 2000 => \n",
       "\n",
       "1077.07 feet 2001 => \n",
       "\n",
       "1053.84 feet 2002 => \n",
       "\n",
       "1053.38 feet 2003 => \n",
       "\n",
       "1098.37 feet 2004 => \n",
       "\n",
       "1094.62 feet 2005 => \n",
       "\n",
       "1085.58 feet 2006 => \n",
       "\n",
       "1095.58 feet 2007 => \n",
       "\n",
       "1090.98 feet 2008 => \n",
       "\n",
       "1088.93 feet 2009 => \n",
       "\n",
       "1086.95 feet 2010 => \n",
       "\n",
       "1088.19 feet)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'level' X 'Lake Mead' X (1990...2010) ==> map({ $_.tail => &f1(|$_) }) ==> my @levels;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract numbers of the obtained LLM results and plot the levels over the corresponding years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+------------+-----------+------------+------------+---+         \n",
       "|                                                          |         \n",
       "+   *                                                      +  1200.00\n",
       "|                                                          |         \n",
       "|                                                          |         \n",
       "|                                                          |         \n",
       "+                                                          +  1150.00\n",
       "|                                                          |         \n",
       "|                  *                                       |         \n",
       "+     *       *       * *            *  *    *             +  1100.00\n",
       "|                *           *            *     * *  * *   |         \n",
       "|          *                                               |         \n",
       "+        *                 *    *  *                       +  1050.00\n",
       "|                                                          |         \n",
       "+---+------------+-----------+------------+------------+---+         \n",
       "    1990.00      1995.00     2000.00      2005.00      2010.00       "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@levels.map({ ($_.key, sub-parser('GeneralNumber', :drop).process($_.value).head) }) ==> text-list-plot(width=>60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined another LLM function, and since the LLM function produces (or it is suppossed to produce) HTML code we use the magic spec `%% html`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th>Column 1</th>\n",
       "    <th>Column 2</th>\n",
       "    <th>Column 3</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Row 1, Cell 1</td>\n",
       "    <td>Row 1, Cell 2</td>\n",
       "    <td>Row 1, Cell 3</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Row 2, Cell 1</td>\n",
       "    <td>Row 2, Cell 2</td>\n",
       "    <td>Row 2, Cell 3</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Row 3, Cell 1</td>\n",
       "    <td>Row 3, Cell 2</td>\n",
       "    <td>Row 3, Cell 3</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Row 4, Cell 1</td>\n",
       "    <td>Row 4, Cell 2</td>\n",
       "    <td>Row 4, Cell 3</td>\n",
       "  </tr>\n",
       "</table>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%% html\n",
    "\n",
    "my &ftbl = llm-function({\"The HTML code of a random table with $^a rows and $^b columns is : \"}, e => 'OpenAI');\n",
    "\n",
    "&ftbl(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed examples of LLM workflows can be found in the article [\"Workflows with LLM functions\"](https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/), [AA1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Number extraction from LLM responses\n",
    "\n",
    "Often LLM return larger number with comma delimiters between the digits. Here is an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "As of July 2020, the population of Niger is estimated to be 24,206,856 people."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $pop = llm-function()(\"What is the population of Niger?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to extract the numbers from those responses is to use the token `<local-number>` provided by the package [\"Intl::Token::Number\"](https://raku.land/zef:guifa/Intl::Token::Number), [MSp1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(｢2020｣\n",
       " local-number => ｢2020｣ ｢24,206,856｣\n",
       " local-number => ｢24,206,856｣)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use Intl::Token::Number;\n",
    "\n",
    "$pop ~~ m:g/ <local-number> /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, a sub-parser from the packatge [\"Text::SubParsers\"](https://raku.land/zef:antononcube/Text::SubParsers), [AAp8], can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$[\"\\n\\nAs of\", DateTime.new(2020,7,1,0,0,0), \", the population of Niger is estimated to be\", 24206856, \"people.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub-parser(Whatever).subparse($pop).raku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## LLM chat objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM chat objects are used to provide context for LLM interactions with different messages.\n",
    "LLM chat objects keep track of the conversation history, so LLM can better understand the meaning of each message.\n",
    "\n",
    "For more involved examples of using LLM chat objects see the article [\"Number guessing games: PaLM vs ChatGPT\"](https://rakuforprediction.wordpress.com/2023/08/06/number-guessing-games-palm-vs-chatgpt/), [AA2].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a chat object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Functions::Chat(chat-id = , llm-evaluator.conf.name = chatpalm, messages.elems = 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $chatObj = llm-chat(\n",
    "    conf=>'ChatPaLM', \n",
    "    prompt => 'You are Raku coding instructor. You are the best Raku programmer and you know Raku documentation very well. You answers are concise, mostly with code');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we give the chat object a message, and specify the output to be in Markdown format using the magic spec `%% markdown`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To get the characters of a string in Raku, you can use the `chars` method. This method returns a list of all the characters in the string. For example, if you have a string called `\"Hello, world!\"`, you can use the `chars` method to get a list of all the characters in the string:\n",
       "\n",
       "```\n",
       "my @characters = \"Hello, world!\".chars;\n",
       "```\n",
       "\n",
       "This will return a list with the following characters:\n",
       "\n",
       "```\n",
       "[H, e, l, l, o, , , w, o, r, l, d, !]\n",
       "```\n",
       "\n",
       "You can also use the `chars` method to get a list of all the characters in a string that match a certain condition. For example, if you want to get a list of all the vowels in the string `\"Hello, world!\"`, you can use the following code:\n",
       "\n",
       "```\n",
       "my @vowels = \"Hello, world!\".chars.grep(/[aeiou]/);\n",
       "```\n",
       "\n",
       "This will return a list with the following characters:\n",
       "\n",
       "```\n",
       "[a, e, o]\n",
       "```\n",
       "\n",
       "You can also use the `chars` method to get a list of all the characters in a string that are not vowels. For example, if you want to get a list of all the consonants in the string `\"Hello, world!\"`, you can use the following code:\n",
       "\n",
       "```\n",
       "my @consonants = \"Hello, world!\".chars.grep(/[^aeiou]/);\n",
       "```\n",
       "\n",
       "This will return a list with the following characters:\n",
       "\n",
       "```\n",
       "[h, l, l, o, , , w, r, d]\n",
       "```"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%% markdown\n",
    "$chatObj.eval('How do you get the characters of a string?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To make the original word from the characters in the previous example, you can use the `join` method. This method takes a list of characters and joins them together into a string. For example, if you have a list of characters called `@characters` with the following characters:\n",
       "\n",
       "```\n",
       "[H, e, l, l, o, , , w, o, r, l, d, !]\n",
       "```\n",
       "\n",
       "You can use the `join` method to join the characters together into the string `\"Hello, world!\"`:\n",
       "\n",
       "```\n",
       "my $word = \"Hello, world!\".join(@characters);\n",
       "```\n",
       "\n",
       "You can also use the `join` method to join the characters together into a string with a specific separator. For example, if you want to join the characters together into the string `\"HELLO, WORLD!\"` with a space as the separator, you can use the following code:\n",
       "\n",
       "```\n",
       "my $word = \"HELLO, WORLD!\".join(@characters, \" \");\n",
       "```"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%% markdown\n",
    "$chatObj.eval('How do you make the original word from the characters in the previous example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Workflows with LLM functions\"](https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"Number guessing games: PaLM vs ChatGPT\"](https://rakuforprediction.wordpress.com/2023/08/06/number-guessing-games-palm-vs-chatgpt/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[Jupyter::Chatbook Raku package](https://github.com/antononcube/Raku-Jupyter-Chatbook),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[WWW::PaLM Raku package](https://github.com/antononcube/Raku-WWW-PaLM),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[Clipboard Raku package](https://github.com/antononcube/Raku-Clipboard),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[Data::Translators Raku package](https://github.com/antononcube/Raku-Data-Translators),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp7] Anton Antonov,\n",
    "[Data::TypeSystem Raku package](https://github.com/antononcube/Raku-Data-TypeSystem),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp8] Anton Antonov,\n",
    "[Text::Plot Raku package](https://github.com/antononcube/Raku-Text-Plot),\n",
    "(2022),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp9] Anton Antonov,\n",
    "[Text::SubParsers Raku package](https://github.com/antononcube/Raku-Text-SubParsers),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[BDp1] Brian Duggan,\n",
    "[Jupyter:Kernel Raku package](https://github.com/bduggan/raku-jupyter-kernel),\n",
    "(2017-2023),\n",
    "[GitHub/bduggan](https://github.com/bduggan).\n",
    "\n",
    "[MSp1] Matthew Stuckwisch,\n",
    "[Intl::Token::Number Raku package](https://github.com/alabamenhu/IntlTokenNumber)\n",
    "(2021-2023),\n",
    "[GitHub/alabamenhu](https://github.com/alabamenhu)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Raku",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/plain",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
