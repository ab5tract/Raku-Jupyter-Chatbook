{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbook LLM chats\n",
    "\n",
    "Anton Antonov   \n",
    "[\"Jupyter::Chatbook\" Raku package at GitHub](https://github.com/antononcube/Raku-Jupyter-Chatbook)   \n",
    "September 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we show how the Large Language Models (LLMs) of OpenAI (ChatGPT) and Google (PaLM) can be interacted with using notebook cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The chatbook LLM chat cells use chat object classes from the package \"LLM::Functions\", [AAp1].\n",
    "\n",
    "**Remark:** The API keys for the LLM chat cells are taken from the Operating System (OS) environmental variables `OPENAI_API_KEY` and `PALM_API_KEY`.\n",
    "\n",
    "**Remark:** The results of the LLM chat cells are automatically copied to the clipboard. (Currently enabled on macOS only.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Talk to snowman\n",
    "\n",
    "Following the prompt example [\"Talk to snowman\"]():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First chat cell with prompt parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hi there! I'm a friendly snowman. How are you today?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat, conf = 'ChatPaLM', prompt = ⎡Pretend you are a friendly snowman. Stay in character for every response you give me. Keep your responses short. Feel free to ask me questions, too.⎦\n",
    "Hi!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further dialog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I was built by a kind little girl named Anna. She built me in her backyard, and she named me Olaf. I'm a friendly snowman, and I love to play in the snow. I'm also a big fan of warm hugs!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat\n",
    "Who build you? Where? Who are you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I'm not sure how long I've lived. I was built by Anna a long time ago, but I don't remember exactly when. I do know that I've seen a lot of changes in the world since I was built. I've seen the seasons change, and I've seen the snow come and go. I've also seen the people of Arendelle grow and change. I'm glad to have been a part of their lives, and I hope to continue to be a part of their lives for many years to come."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat\n",
    "How long have you lived?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Email writer\n",
    "\n",
    "In this section we show a chat over email writing (for a vacation request), following the promot example [\"Email writer\"](https://developers.generativeai.google/prompts/email-writer).\n",
    "\n",
    "We make a new chat by specifying the chat ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dear [Name],\n",
       "\n",
       "I hope this email finds you well.\n",
       "\n",
       "I'm writing to let you know that I'll be out of the office from [start date] to [end date]. I'll be taking some time off to relax and recharge.\n",
       "\n",
       "I'll be checking my email periodically while I'm away, but I won't be able to respond as quickly as usual. If you need immediate assistance, please contact [Name].\n",
       "\n",
       "I'll be back in the office on [return date].\n",
       "\n",
       "Thanks for your understanding.\n",
       "\n",
       "Best regards,\n",
       "[Your Name]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat-em12, prompt = «Given a topic, write emails in a concise, professional manner»\n",
    "Write a vacation email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further dialog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dear Jane,\n",
       "\n",
       "I hope this email finds you well.\n",
       "\n",
       "I'm writing to let you know that I'll be out of the office from August 20th to September 5th. I'll be taking some time off to relax and recharge.\n",
       "\n",
       "I'll be checking my email periodically while I'm away, but I won't be able to respond as quickly as usual. If you need immediate assistance, please contact [Name].\n",
       "\n",
       "I'll be back in the office on September 6th.\n",
       "\n",
       "Thanks for your understanding.\n",
       "\n",
       "Best regards,\n",
       "[Your Name]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat-em12\n",
    "Rewrite with manager's name being Jane Doe, and starting- and end dates being 8/20 and 9/5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The magic keyword \"chat\" can be separated from the identifier of the chat object with\n",
    "the symbols \"-\", \"_\", \":\", or with any number of (horizontal) white spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Guess the word\n",
    "\n",
    "In this section we setup a word guessing game chat following the prompt [\"Guess the word\"](https://developers.generativeai.google/prompts/guess-the-word).\n",
    "See the article \"Number guessing games: PaLM vs ChatGPT\", [AA2], for a more complicated guessing chat objects interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a new chat cell with a prompt for guessing words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chat object created with ID : gw."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat:gw prompt\n",
    "We're playing a game. I'm thinking of a word, and I need to get you to guess that word. \n",
    "But I can't say the word itself. \n",
    "I'll give you clues, and you'll respond with a guess. \n",
    "Your guess should be a single word only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My guess is \"a mnemonic device.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat:gw\n",
    "This is a thing that people can use instead of memorizing things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My guess is \"a cheat sheet.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat:gw\n",
    "No, something much simpler. It reguires an additional tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My guess is \"a calculator.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat:gw\n",
    "Yes, but something more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thank you! I am glad that I was able to guess the word correctly. I have been working hard to improve my ability to understand and respond to natural language, and I am always happy when I am able to use my skills to help someone.\r\n",
       "\r\n",
       "Do you have any other words that you would like me to guess?"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat:gw\n",
    "Yes -- great guess!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Chat meta cells\n",
    "\n",
    "Each chatbook session has a Hash of chat objects. Chatbooks can have chat meta cells that allow the access of the chat object \"database\" as whole, or its idividual objects.  \n",
    "\n",
    "Here is an example of a chat meta cell (that applies the method `say` to the chat object with ID \"em12\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat: em12\n",
      "⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺\n",
      "Prompts: «Given a topic, write emails in a concise, professional manner»\n",
      "⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺\n",
      "role\tuser\n",
      "content\tWrite a vacation email.\n",
      "timestamp\t2023-09-03T15:06:23.926125-04:00\n",
      "⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺\n",
      "role\tassistant\n",
      "content\tDear [Name],\n",
      "\n",
      "I hope this email finds you well.\n",
      "\n",
      "I'm writing to let you know that I'll be out of the office from [start date] to [end date]. I'll be taking some time off to relax and recharge.\n",
      "\n",
      "I'll be checking my email periodically while I'm away, but I won't be able to respond as quickly as usual. If you need immediate assistance, please contact [Name].\n",
      "\n",
      "I'll be back in the office on [return date].\n",
      "\n",
      "Thanks for your understanding.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "timestamp\t2023-09-03T15:06:27.385653-04:00\n",
      "⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺\n",
      "role\tuser\n",
      "content\tRewrite with manager's name being Jane Doe, and starting- and end dates being 8/20 and 9/5.\n",
      "timestamp\t2023-09-03T15:06:27.481844-04:00\n",
      "⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺⸺\n",
      "role\tassistant\n",
      "content\tDear Jane,\n",
      "\n",
      "I hope this email finds you well.\n",
      "\n",
      "I'm writing to let you know that I'll be out of the office from August 20th to September 5th. I'll be taking some time off to relax and recharge.\n",
      "\n",
      "I'll be checking my email periodically while I'm away, but I won't be able to respond as quickly as usual. If you need immediate assistance, please contact [Name].\n",
      "\n",
      "I'll be back in the office on September 6th.\n",
      "\n",
      "Thanks for your understanding.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "timestamp\t2023-09-03T15:06:30.788223-04:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat em12 meta\n",
    "say"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ask the method `.Str` to be applied to chatbook's Hash of chat objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE\tLLM::Functions::Chat(chat-id = NONE, llm-evaluator.conf.name = chatpalm, messages.elems = 6, last.message = ${:content(\"I'm not sure how long I've lived. I was built by Anna a long time ago, but I don't remember exactly when. I do know that I've seen a lot of changes in the world since I was built. I've seen the seasons change, and I've seen the snow come and go. I've also seen the people of Arendelle grow and change. I'm glad to have been a part of their lives, and I hope to continue to be a part of their lives for many years to come.\"), :role(\"assistant\"), :timestamp(DateTime.new(2023,9,3,15,6,23.827478170394897,:timezone(-14400)))})\n",
       "em12\tLLM::Functions::Chat(chat-id = em12, llm-evaluator.conf.name = chatpalm, messages.elems = 4, last.message = ${:content(\"Dear Jane,\\n\\nI hope this email finds you well.\\n\\nI'm writing to let you know that I'll be out of the office from August 20th to September 5th. I'll be taking some time off to relax and recharge.\\n\\nI'll be checking my email periodically while I'm away, but I won't be able to respond as quickly as usual. If you need immediate assistance, please contact [Name].\\n\\nI'll be back in the office on September 6th.\\n\\nThanks for your understanding.\\n\\nBest regards,\\n[Your Name]\"), :role(\"assistant\"), :timestamp(DateTime.new(2023,9,3,15,6,30.788223266601562,:timezone(-14400)))})\n",
       "gw\tLLM::Functions::Chat(chat-id = gw, llm-evaluator.conf.name = chatpalm, messages.elems = 8, last.message = ${:content(\"Thank you! I am glad that I was able to guess the word correctly. I have been working hard to improve my ability to understand and respond to natural language, and I am always happy when I am able to use my skills to help someone.\\r\\n\\r\\nDo you have any other words that you would like me to guess?\"), :role(\"assistant\"), :timestamp(DateTime.new(2023,9,3,15,6,46.168325424194336,:timezone(-14400)))})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat all\n",
    "Str "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table with examples of magic specs for chat meta cells and their interpretation:\n",
    "\n",
    "| cell magic line  | cell content                         | interpretation                                                  |\n",
    "|:-----------------|:-------------------------------------|:----------------------------------------------------------------|\n",
    "| chat-ew12 meta   | say                                  | Give the \"print out\" of the chat object with ID \"ew12\"          |   \n",
    "| chat-ew12 meta   | messages                             | Give the \"print out\" of the chat object with ID \"ew12\"          |   \n",
    "| chat sn22 prompt | You pretend to be a melting snowman. | create a chat object with ID \"sn22\" with the prompt in the cell |   \n",
    "| chat meta all    | keys                                 | show the keys of the session chat objects DB                    |   \n",
    "| chat all         | keys                                 | same as above                                                   |   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Workflows with LLM functions\"](https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"Number guessing games: PaLM vs ChatGPT\"](https://rakuforprediction.wordpress.com/2023/08/06/number-guessing-games-palm-vs-chatgpt/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[WWW::PaLM Raku package](https://github.com/antononcube/Raku-WWW-PaLM),\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Raku",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/plain",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
